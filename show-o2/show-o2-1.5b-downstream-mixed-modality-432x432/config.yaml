wandb:
  entity: null
  resume: auto
  run_id: vjwdlim5
experiment:
  project: show-o2-2b-stage-1
  name: show-o2-1.5b-downstream-mixed-modality-432x432
  output_dir: show-o2-1.5b-downstream-mixed-modality-432x432
  output_dataloader_state_dir: null
  max_train_examples_t2i: 60000000
  max_train_examples_mmu: null
  save_every: 2000
  generate_every: 1000
  log_every: 50
  log_grad_norm_every: 500
  resume_from_checkpoint: latest
  logging_dir: show-o2-1.5b-downstream-mixed-modality-432x432/logs
model:
  vae_model:
    type: wan21
    pretrained_model_path: Wan_VAE_model/Wan2.1_VAE.pth
  showo:
    model_name: Showo2
    load_from_showo: false
    pretrained_model_path: showlab/show-o2-1.5B
    llm_model_path: Qwen/Qwen2.5-1.5B-Instruct
    llm_vocab_size: null
    hidden_size: 1536
    image_latent_dim: 16
    image_latent_height: 27
    image_latent_width: 27
    hq_image_latent_height: 64
    hq_image_latent_width: 64
    mixed_modal_latent_height: 27
    mixed_modal_latent_width: 27
    patch_size: 2
    num_diffusion_layers: 10
    clip_latent_dim: 1152
    add_qk_norm: true
    add_time_embeds: true
    frozen_params:
    - image_embedder_und
    - und_trans
    - showo
    - position_embedding
    params_not_load: null
  clip:
    pretrained_model_path: google/siglip-so400m-patch14-384
  gradient_checkpointing: true
dataset:
  samp_probs: null
  accumulation: 1
  mixed_loader_mode: sequential_max_size_cycle
  params:
    train_mixed_modal_shards_path_or_url: ../AvaMERG_images
    annotation_path: ../AvaMERG_images/test.json
    is_clip_encoder: false
    default_system_prompt: ''
    add_caption_prompt: true
    validation_prompts_file: prompts/t2i_prompts.txt
    shuffle_buffer_size: 1000
    num_workers: 0
    pin_memory: true
    persistent_workers: true
  preprocessing:
    max_seq_length: 1280
    max_hq_seq_length: 4352
    max_mixed_modal_seq_length: 4352
    max_video_seq_length: 4352
    resolution: 432
    mixed_modal_resolution: 432
    video_resolution: 432
    hq_resolution: 1024
    num_t2i_image_tokens: 729
    num_mmu_image_tokens: 729
    num_hq_image_tokens: 4096
    num_mixed_modal_tokens: 729
    num_video_tokens: 3645
    latent_height: ${model.showo.image_latent_height}
    latent_width: ${model.showo.image_latent_width}
    video_latent_height: ${model.showo.image_latent_height}
    video_latent_width: ${model.showo.image_latent_width}
    hq_latent_height: ${model.showo.hq_image_latent_height}
    hq_latent_width: ${model.showo.hq_image_latent_width}
    mixed_modal_latent_height: ${model.showo.hq_image_latent_height}
    mixed_modal_latent_width: ${model.showo.hq_image_latent_width}
    min_res:
    - 256
    - 256
    random_und_or_gen: 0.0
    max_num_images: 4
    max_num_videos: 4
    num_frames: 2
optimizer:
  name: adamw
  params:
    learning_rate: 0.0001
    scale_lr: false
    beta1: 0.9
    beta2: 0.999
    weight_decay: 0.0
    epsilon: 1.0e-08
lr_scheduler:
  scheduler: constant_with_warmup
  params:
    learning_rate: ${optimizer.params.learning_rate}
    warmup_steps: 0
transport:
  path_type: Linear
  prediction: velocity
  loss_weight: null
  train_eps: null
  sample_eps: null
  snr_type: lognorm
  sampling_method: euler
  guidance_scale: 5.0
  num_inference_steps: 50
  atol: 1.0e-06
  rtol: 0.001
  reverse: false
  do_shift: true
  time_shifting_factor: 3.0
training:
  gradient_accumulation_steps: 1
  batch_size: 1
  batch_size_mixed_modal: 1
  batch_size_video: 1
  mixed_precision: bf16
  enable_tf32: true
  seed: 10000
  max_train_steps: 40000
  cond_dropout_prob: 0.1
  label_smoothing: 0.0
  max_grad_norm: 1.0
  ntp_coeff: 0.2
  flow_coeff: 1.0
  und_max_t0: 1.0
accelerate: null
launch: null
--config_file: accelerate_configs/1_gpu.yaml
--main_process_port: 9999
config: configs/showo2_1.5b_downstream_mixed_modality_simple.yaml
