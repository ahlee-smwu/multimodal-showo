wandb:
  entity: null
  resume: auto
  run_id: qs0w4t9k
experiment:
  project: showo2-1.5b-stage-2-release
  name: showo2-1.5b-stage-2-a
  output_dir: showo2-1.5b-stage-2-a
  output_dataloader_state_dir: 64gpus_dataloader_states
  max_train_examples_t2i: 100000000
  max_train_examples_mmu: 100000000
  save_every: 10000000
  eval_every: 2500
  generate_every: 500
  log_every: 50
  log_grad_norm_every: 500
  resume_from_checkpoint: latest
  logging_dir: showo2-1.5b-stage-2-a/logs
model:
  vae_model:
    type: wan21
    pretrained_model_path: Wan_VAE_model/Wan2.1_VAE.pth
  showo:
    model_name: Showo2
    load_from_showo: false
    pretrained_model_path: ''
    llm_model_path: Qwen/Qwen2.5-1.5B-Instruct
    llm_vocab_size: null
    hidden_size: 1536
    image_latent_dim: 16
    image_latent_height: 27
    image_latent_width: 27
    hq_image_latent_height: 64
    hq_image_latent_width: 64
    mixed_modal_latent_height: 27
    mixed_modal_latent_width: 27
    patch_size: 2
    num_diffusion_layers: 10
    clip_latent_dim: 1152
    add_qk_norm: true
    add_time_embeds: true
    frozen_params:
    - showo
    - image_embedder_und
    - und_trans
    - position_embedding
    - image_embedder_gen
    - diffusion
    - diff_proj
    - time_embed_proj
    params_not_load: null
  clip:
    pretrained_model_path: google/siglip-so400m-patch14-384
  gradient_checkpointing: true
dataset:
  samp_probs: null
  accumulation: 1
  mixed_loader_mode: concat_max_size_cycle
  params:
    train_t2i_shards_path_or_url: path/to/your.jsonl
    train_mmu_shards_path_or_url: path/to/your/image/dir
    annotation_path: path/to/blip_laion_cc_sbu_558k.json
    is_clip_encoder: false
    default_system_prompt: ''
    add_caption_prompt: true
    validation_prompts_file: prompts/t2i_prompts.txt
    shuffle_buffer_size: 1000
    num_workers: 6
    pin_memory: true
    persistent_workers: true
  preprocessing:
    max_seq_length: 1024
    max_hq_seq_length: 4352
    max_mixed_modal_seq_length: 5120
    resolution: 432
    hq_resolution: 1024
    mixed_modal_resolution: 432
    num_t2i_image_tokens: 729
    num_mmu_image_tokens: 729
    num_hq_image_tokens: 4096
    num_mixed_modal_tokens: 729
    num_video_tokens: 3645
    latent_height: ${model.showo.image_latent_height}
    latent_width: ${model.showo.image_latent_width}
    hq_latent_height: ${model.showo.hq_image_latent_height}
    hq_latent_width: ${model.showo.hq_image_latent_width}
    mixed_modal_latent_height: ${model.showo.hq_image_latent_height}
    mixed_modal_latent_width: ${model.showo.hq_image_latent_width}
    min_res:
    - 512
    - 512
    random_und_or_gen: 0.0
optimizer:
  name: adamw
  params:
    learning_rate_ve: 5.0e-05
    learning_rate_proj: 5.0e-05
    learning_rate_showo: 5.0e-05
    scale_lr: false
    beta1: 0.9
    beta2: 0.999
    weight_decay: 0.0
    epsilon: 1.0e-08
lr_scheduler:
  scheduler: cosine
  params:
    warmup_steps: null
    warmup_ratio: 0.03
transport:
  path_type: Linear
  prediction: velocity
  loss_weight: null
  train_eps: null
  sample_eps: null
  snr_type: lognorm
  sampling_method: euler
  guidance_scale: 5.0
  num_inference_steps: 50
  atol: 1.0e-06
  rtol: 0.001
  reverse: false
  do_shift: true
  time_shifting_factor: 3.0
training:
  gradient_accumulation_steps: 1
  batch_size_t2i: 4
  batch_size_mmu: 4
  mixed_precision: bf16
  enable_tf32: true
  seed: 10086
  max_train_steps: null
  cond_dropout_prob: 0.1
  label_smoothing: 0.0
  max_grad_norm: 1.0
  ntp_coeff: 1.0
  flow_coeff: 1.0
  stage: pre-training
  noise_und_image: true
  und_max_t0: 1.0
config: configs/showo2_1.5b_stage_2_a_video.yaml
